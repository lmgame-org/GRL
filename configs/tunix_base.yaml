defaults:
  - agents
  - _self_

# ------ Rollout Configuration ------
rollout:
  agent_group_num: [8]
  agent_group_size: [16] # number of agents = agent_group_num * agent_group_size
  validation_agent_group_num: [128]
  validation_agent_group_size: [1]
  training: [simpleSokobanAgent]
  validation: [simpleSokobanAgent]
  validation_seed: 123
  truncation: left  # truncate from left (oldest tokens) to keep recent context
  use_turn_scores: False  # for GAE computation
  rollout_filter_ratio: 0.25  # filter ratio for rollout selection
  rollout_filter_type: std  # std or std_rev for filtering criteria
  reward_normalization:
    grouping: "state" # state / batch / inductive
    method: "identity" # asym_clip / identity / mean_std
  # Lightweight CPU parallelism for prompt building and env stepping
  # 0 or unset -> auto = min(32, os.cpu_count())
  num_prompt_threads: 0
  num_env_threads: 0
  # Show tqdm progress bars for concurrent steps
  show_tqdm: False

# ------ PPO / Training Hyperparameters ------
ppo:
  num_ppo_epochs: 1
  mini_batch_size: 4
  gamma: 1.0
  gae_lambda: 1.0
  beta: 0.001
  epsilon: 0.2
  vf_coef: 1.0
  clip_range_value: 0.5
  entropy_coeff: 0.001
  aggs_mode: token-mean
  clip_ratio_low: 0.2
  clip_ratio_high: 0.28
  clip_ratio_c: 3.0
  kl_penalty_method: k1

training:
  gradient_accumulation_steps: 8
  max_steps: -1  # set -1 to enable max steps based on previous configs
  eval_every_n_steps: -1  # set -1 to enable eval every n steps based on previous configs
  actor_lr: 1.0e-6
  critic_lr: 1.0e-5
  b1: 0.9
  b2: 0.999
  weight_decay: 0.01
  max_grad_norm: 1.0
  save_interval_steps: 500
  max_to_keep: 1

rollout_runtime:
  max_prompt_length: 2048
  total_generation_steps: 100
  temperature_train: 1.0
  temperature_eval: 1.0
  top_p: 1.0
  top_k: null

# ------ Model artifacts ------
model:
  repo_id: Qwen/Qwen2.5-0.5B-Instruct

