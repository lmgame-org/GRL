## Tunix base configuration for PPO training with Sokoban agents
## This mirrors the structure of `configs/base.yaml` for consistency

# ------ Hydra Config ------

defaults:
  - agents
  - _self_

# ------ Rollout Configuration ------
rollout:
  agent_group_num: [8]
  agent_group_size: [16] # number of agents = agent_group_num * agent_group_size
  validation_agent_group_num: [256, 256]
  validation_agent_group_size: [1, 1]
  training: [simpleSokobanAgent]
  validation: [simpleSokobanAgent, largeSokobanAgent]
  validation_seed: 123
  truncation: left  # truncate from left (oldest tokens) to keep recent context
  use_turn_scores: False  # for GAE computation
  rollout_filter_ratio: 0.25  # filter ratio for rollout selection
  rollout_filter_type: std  # std or std_rev for filtering criteria
  reward_normalization:
    grouping: "state" # state / batch / inductive
    method: "identity" # asym_clip / identity / mean_std
  # Lightweight CPU parallelism for prompt building and env stepping
  # 0 or unset -> auto = min(32, os.cpu_count())
  num_prompt_threads: 0
  num_env_threads: 0
  # Show tqdm progress bars for concurrent steps
  show_tqdm: False


# ------ Training Parameters ------

####### PPO hyperparameters used by Tunix PPO #######
NUM_PPO_EPOCHS = 1
MINI_BATCH_SIZE = 1
GAMMA = 1.0
GAE_LAMBDA = 0.95
BETA = 0.0  # Disable KL to reduce memory
EPSILON = 0.2
VF_COEF = 0.1
CLIP_RANGE_VALUE = 0.2

####### Cluster / trainer / rollout configuration #######
# Sharding (fsdp, tp) â€” adjust to available devices
MESH = [(1, 2), ("fsdp", "tp")]

####### Rollout (GRPO generation) parameters #######
MAX_PROMPT_LENGTH = 2048
TOTAL_GENERATION_STEPS =  256
TEMPERATURE = 0.9
TOP_P = 1.0
TOP_K = 50

####### Training loop setup #######
BATCH_SIZE = 1
NUM_BATCHES = 200
NUM_TEST_BATCHES = 100  # not used in this script but kept for completeness
EVAL_EVERY_N_STEPS = 10
NUM_EPOCHS = 1
MAX_STEPS = int(NUM_BATCHES * TRAIN_FRACTION * NUM_EPOCHS)


####### Optimizer/scheduler #######
LEARNING_RATE = 3e-6
B1 = 0.9
B2 = 0.99
WEIGHT_DECAY = 0.1
WARMUP_STEPS = 0.1 * MAX_STEPS
MAX_GRAD_NORM = 0.1


# Checkpointing
INTERMEDIATE_CKPT_DIR = "/home/vanitas/lmgame_projects/GRL/content/intermediate_ckpt/"
CKPT_DIR = "/home/vanitas/lmgame_projects/GRL/content/ckpts/"
SAVE_INTERVAL_STEPS = 500
MAX_TO_KEEP = 4

####### Inference presets (optional) #######
GENERATION_CONFIGS = {
    "greedy": {"temperature": 1e-4, "top_k": 1, "top_p": 1.0},
    "standard": {"temperature": 0.7, "top_k": 50, "top_p": 0.95},
    "liberal": {"temperature": 0.85, "top_k": 2000, "top_p": 1.0},
}